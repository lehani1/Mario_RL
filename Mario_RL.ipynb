{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gym_super_mario_bros==7.3.0 nes_py"
      ],
      "metadata": {
        "id": "n6X_BwmfYmtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "HG8MMZ9nZzNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
      ],
      "metadata": {
        "id": "m2efGrerY7cY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the game environment with gynamsium"
      ],
      "metadata": {
        "id": "VW5BQBL_YmY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIE-_qNwW7dC",
        "outputId": "ab80d96d-6f72-4ee6-b7f3-45946faff699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flag - restart or not\n",
        "done = True\n",
        "# Loop through each frame in the game\n",
        "for step in range(100000):\n",
        "    # Start the game to begin with\n",
        "    if done:\n",
        "        # Start the game\n",
        "        env.reset()\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    env.render()\n",
        "# Close the game\n",
        "env.close()"
      ],
      ,
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the environment\n",
        "The environment the playing agent is exposed to is in RGB color space, that means it has 3 layers to it, Red, Green and Blue. Our goal is to flatten it to only one color channel, specifically grayscale and then vectorize the frames to feed into our model."
      ],
      "metadata": {
        "id": "tfC5rjO5ZRzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.wrappers import GrayScaleObservation\n",
        "# Import Vectorization Wrappers\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "sb896k-uZxY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base environment\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "# Grayscale\n",
        "env = GrayScaleObservation(env, keep_dim=True)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "# Stack the frames\n",
        "env = VecFrameStack(env, 4, channels_order='last')"
      ],
      "metadata": {
        "id": "guwKWHx8aC-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()"
      ],
      "metadata": {
        "id": "MALMx77maHux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state, reward, done, info = env.step([5])"
      ],
      "metadata": {
        "id": "MPUt5S3caKLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,16))\n",
        "for idx in range(state.shape[3]):\n",
        "    plt.subplot(1,4,idx+1)\n",
        "    plt.imshow(state[0][:,:,idx])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M-1G4H9faLec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model using Proximal Policy Optimization (PPO)\n",
        "\n"
      ],
      "metadata": {
        "id": "2m0i_8dEaVP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Import PPO for algos\n",
        "from stable_baselines3 import PPO\n",
        "# Import Base Callback for saving models\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "01_KO0T-aU51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq, save_path, verbose=1):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _init_callback(self):\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
        "            self.model.save(model_path)\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "PEnEMI0JauSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = './train/'\n",
        "LOG_DIR = './logs/'"
      ],
      "metadata": {
        "id": "AhOloJekauLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "OVqEEm69axAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001,\n",
        "            n_steps=512)"
      ],
      "metadata": {
        "id": "cbjkSp3ja0Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=1000000, callback=callback)"
      ],
      "metadata": {
        "id": "CvVhsD96a2TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('thisisatestmodel')\n"
      ],
      "metadata": {
        "id": "ViKoHdsca3tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing out the model"
      ],
      "metadata": {
        "id": "kZXdFu70a5Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO.load('./train/best_model_1000000')\n",
        "state = env.reset()\n",
        "# Loop through the game\n",
        "while True:\n",
        "\n",
        "    action, _ = model.predict(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()"
      ],
      "metadata": {
        "id": "DdEbDVqma7v0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
